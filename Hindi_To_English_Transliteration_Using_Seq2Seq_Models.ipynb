{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hindi to English Transliteration using Sequence to Sequence models\n",
        "\n",
        "The purpose of this notebook is as follows:\n",
        "\n",
        "- Use the Dakshini dataset to get Hindi and English word data for transliteration. A sample of the data is as below\n",
        "```\n",
        "अंकगणित\tankganit\t3\n",
        "अंकल\tuncle\t4\n",
        "अंकुर\tankur\t4\n",
        "```\n",
        "- Create an Encoder-Decoder setup using Pytorch which will be trained on the corpus and tested similarly\n",
        "- Use Encoder-Decoder with Attention and check performance in comparison to without attention\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NoMXOArsr8Pa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2zG_y0sdo_x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "\n",
        "try:\n",
        "  import pytorch_lightning as pl\n",
        "except:\n",
        "  !pip install --quiet pytorch-lightning>=1.5\n",
        "  import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def set_seed(seed):\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  random.seed(seed)\n",
        "\n",
        "set_seed(132)\n"
      ],
      "metadata": {
        "id": "mcMZrSADmfBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get the dataset\n"
      ],
      "metadata": {
        "id": "Zk13nY5qd6Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar"
      ],
      "metadata": {
        "id": "V9sefWORfjug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "990f47cc-a046-41be-f3c1-44e4a1d23888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-06 18:56:26--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.111.207, 142.251.16.207, 172.253.62.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.111.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G  89.2MB/s    in 20s     \n",
            "\n",
            "2024-05-06 18:56:46 (96.4 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf '/content/dakshina_dataset_v1.0.tar'\n",
        "\n",
        "VAL_PATH = '/content/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv'\n",
        "TRAIN_PATH = '/content/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv'\n",
        "TEST_PATH = '/content/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv'\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_PATH, sep='\\t', names=['Hindi', 'English', ''])\n",
        "val_df = pd.read_csv(VAL_PATH, sep='\\t', names=['Hindi', 'English', ''])\n",
        "test_df = pd.read_csv(TEST_PATH, sep='\\t', names=['Hindi', 'English', ''])"
      ],
      "metadata": {
        "id": "aOxbHh0DAXV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8NjzC8okA564",
        "outputId": "440ea930-d922-4ba9-ff5f-a0137f2288ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Hindi   English   \n",
              "0       अं        an  3\n",
              "1  अंकगणित  ankganit  3\n",
              "2     अंकल     uncle  4\n",
              "3    अंकुर     ankur  4\n",
              "4   अंकुरण   ankuran  3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f985f6c6-8c36-4139-803a-4a050ddac5ac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hindi</th>\n",
              "      <th>English</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>अं</td>\n",
              "      <td>an</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>अंकगणित</td>\n",
              "      <td>ankganit</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>अंकल</td>\n",
              "      <td>uncle</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>अंकुर</td>\n",
              "      <td>ankur</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>अंकुरण</td>\n",
              "      <td>ankuran</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f985f6c6-8c36-4139-803a-4a050ddac5ac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f985f6c6-8c36-4139-803a-4a050ddac5ac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f985f6c6-8c36-4139-803a-4a050ddac5ac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6548855e-d944-460b-8110-55bee0ceed33\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6548855e-d944-460b-8110-55bee0ceed33')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6548855e-d944-460b-8110-55bee0ceed33 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 44204,\n  \"fields\": [\n    {\n      \"column\": \"Hindi\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25000,\n        \"samples\": [\n          \"\\u091a\\u093e\\u0902\\u092a\\u093e\",\n          \"\\u0938\\u094d\\u091f\\u0949\\u0915\\u0939\\u094b\\u092e\",\n          \"\\u0924\\u093e\\u0932\\u093e\\u092c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"English\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41344,\n        \"samples\": [\n          \"nishanebaazi\",\n          \"champu\",\n          \"bhej\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          10,\n          4,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train data shape : {train_df.shape}')\n",
        "print(f'Val data shape : {val_df.shape}')\n",
        "print(f'Test data shape : {test_df.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn0n3HXHBFfn",
        "outputId": "4ef04000-377f-4b9c-80f7-f7ad46a15751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape : (44204, 3)\n",
            "Val data shape : (4358, 3)\n",
            "Test data shape : (4502, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To tackle a problematic case of नं\t-> nan\n",
        "train_df.fillna('naan', inplace=True)\n",
        "val_df.fillna('naan', inplace=True)\n",
        "test_df.fillna('naan', inplace=True)"
      ],
      "metadata": {
        "id": "_aCkl28-Mlnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.isna().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmW5lBS8NFpF",
        "outputId": "36f8d893-7fbb-4b83-8c72-a595c89190f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Hindi      False\n",
              "English    False\n",
              "           False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create class 'LangProcess' which will take the language name and its words, and create an object which holds the information required for mapping the language words to its respective and other information related to the corpus."
      ],
      "metadata": {
        "id": "711oK1zSGE-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LangProcess():\n",
        "  def __init__(self, lang_name, lang_data):\n",
        "    '''\n",
        "    lang_name : Name of the language\n",
        "    lang_data : Data for this language (words)\n",
        "    '''\n",
        "    self.lang_name = lang_name\n",
        "    self.char_to_idx = {'SOS':0, 'EOS':1}\n",
        "    self.idx_to_char = {0:'SOS', 1:'EOS'}\n",
        "    self.char_count = {}\n",
        "    self.chars_size = 2\n",
        "    self.chars = ['SOS', 'EOS']\n",
        "    self.max_input_len = 1 #Including EOS\n",
        "\n",
        "    for word in lang_data:\n",
        "      if (len(word)+1)>self.max_input_len:\n",
        "        self.max_input_len = len(word)+1\n",
        "      self.add_char(word)\n",
        "\n",
        "  def add_char(self, word):\n",
        "    #NOTE : If word is 'nan', it is identified by pandas as Nan\n",
        "    #However it is actually index 19536 ie नं\tnan\n",
        "    #Tackling it manually\n",
        "    for char in word:\n",
        "      if char in self.char_to_idx.keys():\n",
        "        #Character already in corpus, simply increment count\n",
        "        self.char_count[char] += 1\n",
        "      else:\n",
        "        self.char_to_idx[char] = self.chars_size\n",
        "        self.idx_to_char[self.chars_size] = char\n",
        "        self.char_count[char] = 1\n",
        "        self.chars_size += 1\n",
        "        self.chars.append(char)\n",
        "\n",
        "  def indices_to_word(self, indices):\n",
        "    word = \"\"\n",
        "    for i in indices:\n",
        "      if i==0 or i==1:\n",
        "        break\n",
        "      word += self.idx_to_char[i]\n",
        "    return word"
      ],
      "metadata": {
        "id": "18U2WQaZCM2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang = LangProcess('Hindi', train_df['Hindi'])\n",
        "output_lang = LangProcess('English', train_df['English'])"
      ],
      "metadata": {
        "id": "EsH3pf-0GhYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_stats(lang_obj):\n",
        "  print(f\"For Language : {lang_obj.lang_name}\")\n",
        "  print(f\"Corpus char - index mapping : {lang_obj.char_to_idx}\")\n",
        "  print(f\"Character size : {lang_obj.chars_size}\")\n",
        "  print(f\"Max input size : {lang_obj.max_input_len}\")\n",
        "\n",
        "display_stats(input_lang)\n",
        "print(\"*********************************\")\n",
        "display_stats(output_lang)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82F3M7TvGrRW",
        "outputId": "b735f57c-66fa-409d-ce85-654c8fa26f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Language : Hindi\n",
            "Corpus char - index mapping : {'SOS': 0, 'EOS': 1, 'अ': 2, 'ं': 3, 'क': 4, 'ग': 5, 'ण': 6, 'ि': 7, 'त': 8, 'ल': 9, 'ु': 10, 'र': 11, 'श': 12, 'द': 13, 'न': 14, 'े': 15, 'भ': 16, '्': 17, 'ष': 18, 'ा': 19, 'ी': 20, 'ठ': 21, 'य': 22, 'ो': 23, 'ू': 24, 'ज': 25, 'च': 26, 'म': 27, 'ट': 28, 'ड': 29, 'व': 30, 'ः': 31, 'ह': 32, 'प': 33, 'ृ': 34, 'स': 35, 'ध': 36, 'ै': 37, '़': 38, 'ब': 39, 'उ': 40, 'ॉ': 41, 'ई': 42, 'ख': 43, 'घ': 44, 'छ': 45, 'ञ': 46, 'फ': 47, 'ओ': 48, 'थ': 49, 'ढ': 50, 'झ': 51, 'ौ': 52, 'आ': 53, 'इ': 54, 'ँ': 55, 'ए': 56, 'ऊ': 57, 'ॅ': 58, 'ऋ': 59, 'ऑ': 60, 'ऐ': 61, 'औ': 62, 'ङ': 63, 'ॐ': 64}\n",
            "Character size : 65\n",
            "Max input size : 20\n",
            "*********************************\n",
            "For Language : English\n",
            "Corpus char - index mapping : {'SOS': 0, 'EOS': 1, 'a': 2, 'n': 3, 'k': 4, 'g': 5, 'i': 6, 't': 7, 'u': 8, 'c': 9, 'l': 10, 'e': 11, 'r': 12, 's': 13, 'h': 14, 'd': 15, 'b': 16, 'y': 17, 'o': 18, 'j': 19, 'z': 20, 'm': 21, 'v': 22, 'w': 23, 'p': 24, 'f': 25, 'x': 26, 'q': 27}\n",
            "Character size : 28\n",
            "Max input size : 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we need to write utility functions to process the input words as as sequence of numbers, based on the character to index mapping. Thus, we would have 2 lists, one for hindi and for english, containing the numeric representation for the words based on character indices."
      ],
      "metadata": {
        "id": "AHXwC-u9b73W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_word_vector(lang_obj, word):\n",
        "  word_mapped = [lang_obj.char_to_idx[char] for char in word]\n",
        "  return word_mapped\n",
        "\n",
        "def create_dataloader(data_df = train_df, batch_size=128, shuffle=True):\n",
        "\n",
        "  data_len = data_df.shape[0]\n",
        "  print(f\"Processing {data_len} entries.....\")\n",
        "\n",
        "  #Initialize a 0 vector for each entry of training input and output data (zero padding the extra values considering max seq length)\n",
        "  input_data = np.zeros((data_len, input_lang.max_input_len), dtype=np.int32)\n",
        "  output_data = np.zeros((data_len, output_lang.max_input_len), dtype=np.int32)\n",
        "\n",
        "  input_words = data_df['Hindi']\n",
        "  output_words = data_df['English']\n",
        "\n",
        "  for idx, (input_w, output_w) in enumerate(zip(input_words, output_words)):\n",
        "    input_indices = create_word_vector(input_lang, input_w)\n",
        "    output_indices = create_word_vector(output_lang, output_w)\n",
        "\n",
        "    input_indices.append(input_lang.char_to_idx['EOS'])\n",
        "    output_indices.append(output_lang.char_to_idx['EOS'])\n",
        "\n",
        "    input_data[idx,:len(input_indices)] = input_indices\n",
        "    output_data[idx,:len(output_indices)] = output_indices\n",
        "\n",
        "  #Now all processing and conversion of words to sequence of char indices is done\n",
        "  #Proceed with torch Dataset and DataLoader creation\n",
        "  #TODO:Dataset and Dataloader\n",
        "\n",
        "  dataset = TensorDataset(\n",
        "      torch.LongTensor(input_data).to(device),\n",
        "      torch.LongTensor(output_data).to(device)\n",
        "      )\n",
        "\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4)\n",
        "\n",
        "  return dataloader\n",
        "\n"
      ],
      "metadata": {
        "id": "R2Ss3p3IG_FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = create_dataloader(train_df, 128, True)\n",
        "val_dataloader = create_dataloader(val_df, 128, False)\n",
        "test_dataloader = create_dataloader(test_df, 128, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jyusxGJsmem",
        "outputId": "8e8bb2f1-ea8b-43af-a843-847265e69e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 44204 entries.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 4358 entries.....\n",
            "Processing 4502 entries.....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataloader))[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJnuaHBRs6SV",
        "outputId": "0cc99a56-8931-41dc-c3c1-0a8cdd20329b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataloader))[1].view(-1, ).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUNI0KBAVGYS",
        "outputId": "10ac9995-b0ec-4eb1-f861-43e8f5fa78ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2688])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder - Decoder architecture using Pytorch\n",
        "\n"
      ],
      "metadata": {
        "id": "10OPViVtvi4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    #Below module will convert a word of n chars (ie sequence of n char indices) to n vectors of size hdden_size\n",
        "    # inp = torch.LongTensor([1,12,32])\n",
        "    # emb = nn.Embedding(33, 5)\n",
        "    # tensor([[ 1.0509, -0.6933, -1.6445,  0.4131,  1.0456],\n",
        "    #   [ 0.0117, -0.8146,  0.3862, -0.7615,  0.5252],\n",
        "    #   [ 1.1112, -0.6562, -0.8455, -1.5215,  1.4525]],\n",
        "    #  grad_fn=<EmbeddingBackward0>)\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.GRU = nn.GRU(hidden_size, hidden_size, batch_first=True) #indication that the first dimension would be batch_size\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "  def forward(self, input):\n",
        "    #1. Embed the input vector of n indexes -> n vectors of vector (each of hidden_size) ie (n,hidden_size)\n",
        "    #2. Pass this through dropout (reglarization)\n",
        "    #3. Now, pass this sequence of inputs to the GRU, to get output and final hidden state (sequences are managed internally)\n",
        "    embedded = self.dropout(self.embedding(input))\n",
        "    output, hidden = self.GRU(embedded)\n",
        "\n",
        "    return output, hidden\n",
        "\n"
      ],
      "metadata": {
        "id": "LnDg86-Y6WrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, output_size, hidden_size, dropout=0.1):\n",
        "\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.GRU = nn.GRU(hidden_size, hidden_size, batch_first = True)\n",
        "    self.linear = nn.Linear(hidden_size, output_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, encoder_output, hidden, target_outputs=None):\n",
        "    #The decoder gets the hidden state of the last encoder (ie. context vector) and the batch of decoder target inputs\n",
        "    #Initially, we pass the batch's first input token as the SOS token\n",
        "    #Then, during training, teacher forcing is used (original output token passed as next input)\n",
        "    batch_size  = encoder_output.shape[0]\n",
        "    decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(output_lang.char_to_idx['SOS'])\n",
        "    decoder_hidden = hidden\n",
        "    decoder_outputs = []\n",
        "\n",
        "    for idx in range(output_lang.max_input_len):\n",
        "      decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
        "      decoder_outputs.append(decoder_output)\n",
        "\n",
        "      #In training phase, target outputs will be passed. This is used to track if teacher forcing should be used or not\n",
        "      if target_outputs is not None:\n",
        "        #Teacher forcing\n",
        "        decoder_input = target_outputs[:,idx].unsqueeze(1)\n",
        "      else:\n",
        "        #Use decoder previous output as new input during inference\n",
        "        #top_indices holds the largest prob value index for next output token (per input of the batch)\n",
        "        #https://stackoverflow.com/questions/57237352/what-does-unsqueeze-do-in-pytorch\n",
        "        top_vals, top_indices = decoder_output.topk(1)\n",
        "        decoder_input = top_indices.squeeze(-1).detach()\n",
        "\n",
        "    #print(f\"decoder_outputs dim before : {len(decoder_outputs)} x {decoder_outputs[0].shape}\")\n",
        "    #decoder_outputs dim before : 21 x torch.Size([128, 1, 28])\n",
        "    decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "    #print(f\"decoder_outputs dim after : {len(decoder_outputs)} x {decoder_outputs[0].shape}\")\n",
        "    #decoder_outputs dim after : 128 x torch.Size([21, 28])\n",
        "    decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "    #print(f\"decoder_outputs dim post softmax : {len(decoder_outputs)} x {decoder_outputs[0].shape}\")\n",
        "    #decoder_outputs dim post softmax : 128 x torch.Size([21, 28])\n",
        "\n",
        "    return decoder_outputs, decoder_hidden, None #Added extra none because while using attention, we'll pass attention weights\n",
        "\n",
        "  def forward_step(self, input, hidden):\n",
        "      embedded = self.embedding(input)\n",
        "      embedded = F.relu(embedded)\n",
        "      output, hidden = self.GRU(embedded, hidden)\n",
        "      output = self.linear(output)\n",
        "      return output, hidden"
      ],
      "metadata": {
        "id": "yRrZXJ8wA_hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Training related functionalities"
      ],
      "metadata": {
        "id": "aSEn_bWhZMWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, encoder, decoder, loss_fn, encoder_optimizer, decoder_optimizer):\n",
        "\n",
        "  #For each batch of data:\n",
        "  #1. Pass data, labels to device (already done in dataloader)\n",
        "  #2. Pass data to encoder, get outputs, hidden\n",
        "  #3. Pass data to decoder, get predictions for batch\n",
        "  #4. Set gradient to 0 for optimizer(encoder and decoder)\n",
        "  #5. Compute loss\n",
        "  #6. loss backward pass\n",
        "  #7. Optimizer step (encoder and decoder)\n",
        "  #8. Increment the total loss with the loss for this batch\n",
        "  # After all loops, return aggregate loss for this epoch\n",
        "\n",
        "  total_loss = []\n",
        "\n",
        "  for batch in dataloader:\n",
        "    data, target = batch\n",
        "\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    encoder_output, encoder_hidden = encoder(data)\n",
        "    decoder_output, decoder_hidden, _ = decoder(encoder_output, encoder_hidden, target)\n",
        "\n",
        "    # print(f\"Shape in loss : {decoder_output.shape}\")\n",
        "    # print(f\"Dim preds : {decoder_output.view(-1, decoder_output.size(-1)).shape}\")\n",
        "    # print(f\"Dim labels : {target.view(-1).shape}\")\n",
        "\n",
        "    #Dim labels : torch.Size([2688]) where 2688 = 128*21 (Batch size*max word length)\n",
        "    #Dim preds : torch.Size([2688, 28])\n",
        "    loss = loss_fn(\n",
        "        decoder_output.view(-1, decoder_output.size(-1)),\n",
        "        target.view(-1)\n",
        "    )\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    total_loss.append(loss.item())\n",
        "\n",
        "  return sum(total_loss)/len(total_loss)\n"
      ],
      "metadata": {
        "id": "qXg94JmIY48e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(encoder, decoder, encoder_optimizer, decoder_optimizer, loss_fn, epochs = 10):\n",
        "\n",
        "  for e in range(epochs):\n",
        "    loss = train_epoch(train_dataloader, encoder, decoder, loss_fn, encoder_optimizer, decoder_optimizer)\n",
        "    print(f\"Epoch {e} : Loss {loss}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_iSxFehSg08b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "encoder = Encoder(input_lang.chars_size, hidden_size).to(device)\n",
        "decoder = Decoder(output_lang.chars_size, hidden_size).to(device)\n",
        "\n",
        "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.NLLLoss()\n",
        "\n",
        "train(encoder, decoder, encoder_optimizer, decoder_optimizer, loss_fn, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeKZRljwjrVK",
        "outputId": "4e18db9b-2d19-45c2-bf55-ade012cf388b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 : Loss 0.5638245147776741\n",
            "Epoch 1 : Loss 0.330467631448211\n",
            "Epoch 2 : Loss 0.2822112492743255\n",
            "Epoch 3 : Loss 0.25825673350364486\n",
            "Epoch 4 : Loss 0.2421217335528032\n",
            "Epoch 5 : Loss 0.2307418474141573\n",
            "Epoch 6 : Loss 0.2248903665411679\n",
            "Epoch 7 : Loss 0.21667454219450152\n",
            "Epoch 8 : Loss 0.21285596937802487\n",
            "Epoch 9 : Loss 0.20875625101300332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(encoder, decoder, loss_fn, dataloader):\n",
        "\n",
        "  overall_loss = []\n",
        "  with torch.no_grad():\n",
        "    for data in dataloader:\n",
        "      input, target = data\n",
        "      input = input.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      encoder_output, encoder_hidden = encoder(input)\n",
        "      decoder_output, _, _ = decoder(encoder_output, encoder_hidden)\n",
        "\n",
        "      loss = loss_fn(\n",
        "        decoder_output.view(-1, decoder_output.size(-1)),\n",
        "        target.view(-1)\n",
        "      )\n",
        "\n",
        "      overall_loss.append(loss.item())\n",
        "\n",
        "      #Print 1 random input from batch along with its output and prediction\n",
        "      idx = random.randint(0,input.shape[0]-1)\n",
        "      input_indices = input[idx]\n",
        "      target_indices = target[idx]\n",
        "      pred_indices = []\n",
        "      for i in range(len(decoder_output[idx])):\n",
        "        pred_indices.append(torch.argmax(decoder_output[idx][i]).item())\n",
        "\n",
        "      input_word = input_lang.indices_to_word(input_indices.tolist())\n",
        "      target_word = output_lang.indices_to_word(target_indices.tolist())\n",
        "      pred_word = output_lang.indices_to_word(pred_indices)\n",
        "      print(\"***********************************\")\n",
        "      print(f\"Input : {input_word}\")\n",
        "      print(f\"Target : {target_word}\")\n",
        "      print(f\"Pred : {pred_word}\")\n",
        "      print(\"***********************************\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fuPbyYjteWpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(encoder, decoder, loss_fn, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbUVQwGmiyVN",
        "outputId": "0bd96200-55a5-4f2c-8e6a-0f5dc64bda07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***********************************\n",
            "Input : अंतः\n",
            "Target : antaha\n",
            "Pred : antoh\n",
            "***********************************\n",
            "***********************************\n",
            "Input : अवैज्ञानिक\n",
            "Target : avaigyanic\n",
            "Pred : avagyanik\n",
            "***********************************\n",
            "***********************************\n",
            "Input : आवाज़ों\n",
            "Target : aawajon\n",
            "Pred : aavajon\n",
            "***********************************\n",
            "***********************************\n",
            "Input : ईए\n",
            "Target : ea\n",
            "Pred : in\n",
            "***********************************\n",
            "***********************************\n",
            "Input : एलर्जिक\n",
            "Target : allergic\n",
            "Pred : eliruci\n",
            "***********************************\n",
            "***********************************\n",
            "Input : करपात्री\n",
            "Target : karpatri\n",
            "Pred : karapatri\n",
            "***********************************\n",
            "***********************************\n",
            "Input : किल्लत\n",
            "Target : killat\n",
            "Pred : killat\n",
            "***********************************\n",
            "***********************************\n",
            "Input : गांठों\n",
            "Target : ganthon\n",
            "Pred : ganthon\n",
            "***********************************\n",
            "***********************************\n",
            "Input : चढ़ने\n",
            "Target : chadhne\n",
            "Pred : chadhne\n",
            "***********************************\n",
            "***********************************\n",
            "Input : ची\n",
            "Target : chi\n",
            "Pred : chi\n",
            "***********************************\n",
            "***********************************\n",
            "Input : जलभराव\n",
            "Target : jalbharav\n",
            "Pred : jalbhavar\n",
            "***********************************\n",
            "***********************************\n",
            "Input : ज्ञापित\n",
            "Target : gyapit\n",
            "Pred : gyapit\n",
            "***********************************\n",
            "***********************************\n",
            "Input : डराते\n",
            "Target : darate\n",
            "Pred : darate\n",
            "***********************************\n",
            "***********************************\n",
            "Input : दर्प\n",
            "Target : darp\n",
            "Pred : darp\n",
            "***********************************\n",
            "***********************************\n",
            "Input : दिता\n",
            "Target : dita\n",
            "Pred : dita\n",
            "***********************************\n",
            "***********************************\n",
            "Input : धस्माना\n",
            "Target : dhasmana\n",
            "Pred : dhamaana\n",
            "***********************************\n",
            "***********************************\n",
            "Input : नौवहन\n",
            "Target : nauvahan\n",
            "Pred : naunhan\n",
            "***********************************\n",
            "***********************************\n",
            "Input : पम्मी\n",
            "Target : pammi\n",
            "Pred : pamai\n",
            "***********************************\n",
            "***********************************\n",
            "Input : पुतला\n",
            "Target : putlaa\n",
            "Pred : putla\n",
            "***********************************\n",
            "***********************************\n",
            "Input : प्रशासनों\n",
            "Target : prashansanon\n",
            "Pred : prashaason\n",
            "***********************************\n",
            "***********************************\n",
            "Input : फिजिशियन\n",
            "Target : physician\n",
            "Pred : phijistiyon\n",
            "***********************************\n",
            "***********************************\n",
            "Input : बहामास\n",
            "Target : bahamaas\n",
            "Pred : bahamas\n",
            "***********************************\n",
            "***********************************\n",
            "Input : बुलाओ\n",
            "Target : bulao\n",
            "Pred : buloo\n",
            "***********************************\n",
            "***********************************\n",
            "Input : मंगेश\n",
            "Target : mangesh\n",
            "Pred : mangesh\n",
            "***********************************\n",
            "***********************************\n",
            "Input : मरमर\n",
            "Target : murmur\n",
            "Pred : marmar\n",
            "***********************************\n",
            "***********************************\n",
            "Input : मैनन\n",
            "Target : mainan\n",
            "Pred : mainan\n",
            "***********************************\n",
            "***********************************\n",
            "Input : रिग्स\n",
            "Target : riggs\n",
            "Pred : risg\n",
            "***********************************\n",
            "***********************************\n",
            "Input : लकीर\n",
            "Target : lakir\n",
            "Pred : lakir\n",
            "***********************************\n",
            "***********************************\n",
            "Input : लुईस\n",
            "Target : luis\n",
            "Pred : luci\n",
            "***********************************\n",
            "***********************************\n",
            "Input : वाण\n",
            "Target : vaan\n",
            "Pred : wan\n",
            "***********************************\n",
            "***********************************\n",
            "Input : वेलवेट\n",
            "Target : velvet\n",
            "Pred : velet\n",
            "***********************************\n",
            "***********************************\n",
            "Input : संशयों\n",
            "Target : sanshyon\n",
            "Pred : sanshyon\n",
            "***********************************\n",
            "***********************************\n",
            "Input : सहूलियत\n",
            "Target : sahuuliyata\n",
            "Pred : sahuliti\n",
            "***********************************\n",
            "***********************************\n",
            "Input : सुधारगृह\n",
            "Target : sudhargrih\n",
            "Pred : sudharigar\n",
            "***********************************\n",
            "***********************************\n",
            "Input : स्लाइडर\n",
            "Target : slider\n",
            "Pred : slider\n",
            "***********************************\n",
            "***********************************\n",
            "Input : हेगडे\n",
            "Target : hegde\n",
            "Pred : hegde\n",
            "***********************************\n"
          ]
        }
      ]
    }
  ]
}